{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "# from tqdm.notebook import tqdm, trange\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_to_idx = {\n",
    "    \"anger\": 0,\n",
    "    \"fear\": 1,\n",
    "    \"joy\": 2,\n",
    "    \"love\": 3,\n",
    "    \"sadness\": 4,\n",
    "}\n",
    "idx_to_emotion = {v: k for k, v in emotion_to_idx.items()}\n",
    "UNK = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_data(train_data_path, val_data_path, test_data_path):\n",
    "    with open(train_data_path) as training_f:\n",
    "        training = training_f.read().split(\"\\n\")[1:-1]\n",
    "    with open(val_data_path) as valid_f:\n",
    "        validation = valid_f.read().split(\"\\n\")[1:-1]\n",
    "    with open(test_data_path) as testing_f:\n",
    "        testing = testing_f.read().split(\"\\n\")[1:-1]\n",
    "    tra = []\n",
    "    val = []\n",
    "    test = []\n",
    "    for elt in training:\n",
    "        if elt == '':\n",
    "            continue\n",
    "        txt, emotion = elt.split(\",\")\n",
    "        tra.append((txt.split(\" \"), emotion_to_idx[emotion]))\n",
    "    for elt in validation:\n",
    "        if elt == '':\n",
    "            continue\n",
    "        txt, emotion = elt.split(\",\")\n",
    "        val.append((txt.split(\" \"), emotion_to_idx[emotion]))\n",
    "    for elt in testing:\n",
    "        if elt == '':\n",
    "            continue\n",
    "        txt = elt\n",
    "        test.append(txt.split(\" \"))\n",
    "    return tra, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(data):\n",
    "    vocab = set()\n",
    "    for document, _ in data:\n",
    "        for word in document:\n",
    "            vocab.add(word)\n",
    "    return vocab \n",
    "\n",
    "\n",
    "def make_indices(vocab):\n",
    "\tvocab_list = sorted(vocab)\n",
    "\tvocab_list.append(UNK)\n",
    "\tword2index = {}\n",
    "\tindex2word = {}\n",
    "\tfor index, word in enumerate(vocab_list):\n",
    "\t\tword2index[word] = index \n",
    "\t\tindex2word[index] = word \n",
    "\tvocab.add(UNK)\n",
    "\treturn vocab, word2index, index2word \n",
    "\n",
    "\n",
    "def convert_to_vector_representation(data, word2index, test=False):\n",
    "\tif test:\n",
    "\t\tvectorized_data = []\n",
    "\t\tfor document in data:\n",
    "\t\t\tvector = torch.zeros(len(word2index)) \n",
    "\t\t\tfor word in document:\n",
    "\t\t\t\tindex = word2index.get(word, word2index[UNK])\n",
    "\t\t\t\tvector[index] += 1\n",
    "\t\t\tvectorized_data.append(vector)\n",
    "\telse:\n",
    "\t\tvectorized_data = []\n",
    "\t\tfor document, y in data:\n",
    "\t\t\tvector = torch.zeros(len(word2index)) \n",
    "\t\t\tfor word in document:\n",
    "\t\t\t\tindex = word2index.get(word, word2index[UNK])\n",
    "\t\t\t\tvector[index] += 1\n",
    "\t\t\tvectorized_data.append((vector, y))\n",
    "\treturn vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"EmotionDataset is a torch dataset to interact with the emotion data.\n",
    "\n",
    "    :param data: The vectorized dataset with input and expected output values\n",
    "    :type data: List[Tuple[List[torch.Tensor], int]]\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.X = torch.cat([X.unsqueeze(0) for X, _ in data])\n",
    "        self.y = torch.LongTensor([y for _, y in data])\n",
    "        self.len = len(data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"__len__ returns the number of samples in the dataset.\n",
    "\n",
    "        :returns: number of samples in dataset\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"__getitem__ returns the tensor, output pair for a given index\n",
    "\n",
    "        :param index: index within dataset to return\n",
    "        :type index: int\n",
    "        :returns: A tuple (x, y) where x is model input and y is our label\n",
    "        :rtype: Tuple[torch.Tensor, int]\n",
    "        \"\"\"\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "def get_data_loaders(train, val, batch_size=16):\n",
    "    dataset = EmotionDataset(train + val)\n",
    "    train_indices = [i for i in range(len(train))]\n",
    "    val_indices = [i for i in range(len(train), len(train) + len(val))]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    \n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, val, test = fetch_data('dataset/train.txt', 'dataset/val.txt', 'dataset/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = make_vocab(train)\n",
    "vocab, word2index, index2word = make_indices(vocab)\n",
    "train_vectorized = convert_to_vector_representation(train, word2index)\n",
    "val_vectorized = convert_to_vector_representation(val, word2index)\n",
    "test_vectorized = convert_to_vector_representation(test, word2index, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_data_loaders(train_vectorized, val_vectorized, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_device = lambda : \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unk = '<UNK>'\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "\tdef __init__(self, input_dim, h, output_dim):\n",
    "\t\tsuper(FFNN, self).__init__()\n",
    "\t\tself.h = h\n",
    "\t\tself.W1 = nn.Linear(input_dim, h)\n",
    "\t\tself.activation = nn.ReLU()\n",
    "\t\tself.W2 = nn.Linear(h, output_dim)\n",
    "\t\tself.softmax = nn.LogSoftmax(dim=1) \n",
    "\t\tself.loss = nn.NLLLoss() \n",
    "\n",
    "\tdef compute_Loss(self, predicted_vector, gold_label):\n",
    "\t\treturn self.loss(predicted_vector, gold_label)\n",
    "\n",
    "\tdef forward(self, input_vector):\n",
    "\t\tz1 = self.W1(input_vector)\n",
    "\t\tz2 = self.activation(z1)\n",
    "\t\tz3 = self.W2(z2)\n",
    "\t\treturn self.softmax(z3)\n",
    "\t\n",
    "\tdef load_model(self, save_path):\n",
    "\t\tself.load_state_dict(torch.load(save_path))\n",
    "\t\n",
    "\tdef save_model(self, save_path):\n",
    "\t\ttorch.save(self.state_dict(), save_path)\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer):\n",
    "\tmodel.train()\n",
    "\ttotal = 0\n",
    "\tloss = 0\n",
    "\tcorrect = 0\n",
    "\tfor (input_batch, expected_out) in train_loader:\n",
    "\t\toptimizer.zero_grad() \n",
    "\t\toutput = model(input_batch.to(get_device()))\n",
    "\t\t#print(output)\n",
    "\t\ttotal += output.size()[0]\n",
    "\t\t_, predicted = torch.max(output, 1)\n",
    "\t\tcorrect += (expected_out == predicted.to(\"cpu\")).cpu().numpy().sum()\n",
    "\t\tloss = model.compute_Loss(output, expected_out.to(get_device()))\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\tprint('Accuracy: ' + str(correct/total))\n",
    "\treturn\n",
    "\n",
    "\n",
    "def evaluation(model, val_loader, optimizer):\n",
    "\tmodel.eval()\n",
    "\tloss = 0\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\tfor (input_batch, expected_out) in val_loader:\n",
    "\t\toutput = model(input_batch.to(get_device()))\n",
    "\t\ttotal += output.size()[0]\n",
    "\t\t_, predicted = torch.max(output, 1)\n",
    "\t\tcorrect += (expected_out.to(\"cpu\") == predicted.to(\"cpu\")).cpu().numpy().sum()\n",
    "\n",
    "\t\tloss += model.compute_Loss(output, expected_out.to(get_device()))\n",
    "\tloss /= len(val_loader)\n",
    "\tprint('Validation Accuracy: ' + str(correct/total))\n",
    "\tpass\n",
    "\n",
    "def train_and_evaluate(number_of_epochs, model, train_loader, val_loader):\n",
    "\toptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\tfor epoch in range(number_of_epochs):\n",
    "\t\ttrain_epoch(model, train_loader, optimizer)\n",
    "\tevaluation(model, val_loader, optimizer)\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3485\n",
      "Accuracy: 0.7208\n",
      "Validation Accuracy: 0.7889328063241107\n"
     ]
    }
   ],
   "source": [
    "h = 512\n",
    "model = FFNN(len(vocab), h, len(emotion_to_idx)).to(get_device())\n",
    "train_and_evaluate(2, model, train_loader, val_loader)\n",
    "# model.save_model(\"ffnn_fixed.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_preprocessing(data, test=False):\n",
    "    \"\"\"rnn_preprocessing\n",
    "\n",
    "    :param data:\n",
    "    :type data:\n",
    "    :param test:\n",
    "    :type test:\n",
    "    \"\"\"\n",
    "    # Do some preprocessing similar to convert_to_vector_representation\n",
    "    # For the RNN, remember that instead of a single vector per training\n",
    "    # example, you will have a sequence of vectors where each vector\n",
    "    # represents some information about a specific token.\n",
    "\n",
    "    # Add padding to ensure sequences have the same lengths, used in the \n",
    "    # second lstm model\n",
    "    seq_length = 200\n",
    "    for item in data:\n",
    "        if len(item) >= seq_length:\n",
    "            data.append(data[:seq_length])\n",
    "        else:\n",
    "            data.append([0]*(seq_length-len(data)) + data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\tdef __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "\t\tsuper(RNN, self).__init__()\n",
    "\t\t# Fill in relevant parameters \n",
    "\t\tself.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\t\tself.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "\t\tself.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\t\tself.softmax = nn.LogSoftmax(dim=1) \n",
    "\t\tself.loss = nn.NLLLoss()\n",
    "\t\n",
    "\tdef compute_Loss(self, predicted_vector, gold_label):\n",
    "\t\treturn self.loss(predicted_vector, gold_label)\n",
    "\n",
    "\tdef forward(self, inputs):\n",
    "\t\tembedded = self.embedding(torch.Tensor.long(inputs))\n",
    "\t\toutput, hidden = self.rnn(embedded)\n",
    "\t\trst = self.fc(hidden.squeeze(0))\n",
    "\t\treturn self.softmax(rst)\n",
    "\n",
    "\tdef load_model(self, save_path):\n",
    "\t\tself.load_state_dict(torch.load(save_path))\n",
    "\t\n",
    "\tdef save_model(self, save_path):\n",
    "\t\ttorch.save(self.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3301\n",
      "Accuracy: 0.7098\n",
      "Validation Accuracy: 0.7779\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNN(len(vocab), 100, 256, len(emotion_to_idx)).to(get_device())\n",
    "train_and_evaluate(2, rnn_model, train_loader, val_loader)\n",
    "# rnn_model.save_model(\"rnn_fixed.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout_p = 0.3):\n",
    "        super(LSTM, self).__init__()       \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first = True, dropout = dropout_p)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def compute_Loss(self, predicted_vector, gold_label):\n",
    "        return self.loss(predicted_vector, gold_label)\n",
    "           \n",
    "    def forward(self, inputs):                                        \n",
    "        embedded = self.embedding(inputs)   \n",
    "        lstm_out, h = self.lstm(embedded)        \n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        return self.softmax(fc_out)[:, -1], h\n",
    "    \n",
    "    def init_hidden(self, batch_size): \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        weights = next(self.parameters()).data\n",
    "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        return h\n",
    "\n",
    "    def load_model(self, save_path):\n",
    "        self.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        torch.save(self.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3677\n",
      "Accuracy: 0.7512\n",
      "Validation Accuracy: 0.8391\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM(len(vocab), 100, 256, len(emotion_to_idx), 2).to(get_device())\n",
    "train_and_evaluate(2, lstm_model, train_loader, val_loader)\n",
    "# lstm_model.save_model(\"lstm_fixed.pth\") # Save our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
